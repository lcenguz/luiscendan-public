# Tools - .agent

Este directorio contiene herramientas ejecutables y scripts reutilizables para funcionalidades de `.agent`.

## üìÅ Herramientas Disponibles

### healthcare_evaluator.py

Herramientas para evaluaci√≥n de modelos de IA m√©dica.

**Funciones principales**:
- `calculate_rouge()` - M√©tricas ROUGE (overlap l√©xico)
- `calculate_bertscore()` - Similitud sem√°ntica
- `calculate_exact_match()` - Coincidencia exacta
- `evaluate_factual_consistency()` - Consistencia factual (TBFact simplificado)
- `model_as_judge_evaluate()` - Evaluaci√≥n basada en LLM
- `compare_models()` - Comparaci√≥n de m√∫ltiples modelos
- `generate_evaluation_report()` - Generaci√≥n de reportes

**Uso**:
```python
from tools.healthcare_evaluator import calculate_rouge, calculate_bertscore

reference = "Patient diagnosed with Type 2 diabetes"
generated = "Patient has diabetes type 2"

# ROUGE
rouge_scores = calculate_rouge(reference, generated)
print(rouge_scores)

# BERTScore
bert_scores = calculate_bertscore(reference, generated)
print(bert_scores)
```

**Requisitos**:
```bash
pip install evaluate rouge-score bert-score openai
```

---

### pdf_analyzer.py

Herramienta para leer, analizar y generar res√∫menes HTML de PDFs acad√©micos.

**Funciones principales**:
- `PDFAnalyzer.extract_text()` - Extrae texto con m√∫ltiples m√©todos (PyPDF2, pdfminer)
- `PDFAnalyzer.get_sections()` - Detecta secciones autom√°ticamente
- `PDFAnalyzer.get_statistics()` - Estad√≠sticas del documento
- `PDFAnalyzer.generate_summary()` - Genera resumen autom√°tico
- `PDFAnalyzer.generate_html()` - Crea HTML con dise√±o profesional
- `PDFAnalyzer.save_text()` - Guarda texto plano

**Uso desde l√≠nea de comandos**:
```bash
# Analizar un PDF y generar HTML
python .agent/tools/pdf_analyzer.py "documento.pdf"

# Ver estad√≠sticas
python .agent/tools/pdf_analyzer.py "documento.pdf" --stats

# Ver resumen r√°pido
python .agent/tools/pdf_analyzer.py "documento.pdf" --summary

# Guardar texto plano
python .agent/tools/pdf_analyzer.py "documento.pdf" --text output.txt
```

**Uso program√°tico**:
```python
from tools.pdf_analyzer import PDFAnalyzer

# Crear analizador
analyzer = PDFAnalyzer("documento.pdf")

# Extraer texto
text = analyzer.extract_text(method="auto")

# Obtener estad√≠sticas
stats = analyzer.get_statistics()
print(f"P√°ginas: {stats['num_pages']}, Palabras: {stats['num_words']}")

# Generar HTML
analyzer.generate_html("output.html", title="Mi Documento")
```

**Requisitos**:
```bash
pip install PyPDF2 pdfminer.six
```

---

### batch_process_pdfs.py

Procesamiento en batch de m√∫ltiples PDFs.

**Uso**:
```bash
# Procesar todos los PDFs de una asignatura
python .agent/tools/batch_process_pdfs.py --subject SM141500_Analisis_Informacion

# Procesar un directorio espec√≠fico
python .agent/tools/batch_process_pdfs.py --input teoria/ --output apuntes/
```

**Documentaci√≥n completa**: Ver [README_pdf_analyzer.md](README_pdf_analyzer.md)

---

## üîó Recursos Relacionados

- **Skill**: [healthcare-ai-evaluator](../skills/healthcare-ai-evaluator/SKILL.md)
- **Knowledge**: 
  - [healthcare-ai-evaluation.md](../knowledge/healthcare-ai-evaluation.md)
  - [evaluation-metrics-guide.md](../knowledge/evaluation-metrics-guide.md)
- **Repositorio fuente**: `c:\Github-Personal\luiscendan-private\healthcare-ai-model-evaluator`

## üí° Agregar Nuevas Herramientas

Para agregar una nueva herramienta:

1. Crear archivo Python en este directorio
2. Documentar funciones con docstrings
3. Agregar ejemplo de uso en este README
4. Actualizar el generador HTML si es necesario

## üìä Ejemplo Completo

```python
from tools.healthcare_evaluator import (
    calculate_text_metrics,
    evaluate_factual_consistency,
    generate_evaluation_report
)

# Datos
reference = "Patient diagnosed with acute myocardial infarction..."
generated = "Patient has heart attack..."
source = "Patient presents with chest pain, ECG shows ST elevation..."

# M√©tricas autom√°ticas
auto_metrics = calculate_text_metrics(
    reference=reference,
    generated=generated,
    metrics=["rouge", "bertscore"]
)

# Consistencia factual
factual_score = evaluate_factual_consistency(
    source=source,
    summary=generated
)

# Generar reporte
report = generate_evaluation_report(
    auto_metrics=auto_metrics,
    factual_score=factual_score,
    output_path="evaluation_report.json"
)

print("‚úÖ Evaluaci√≥n completa!")
```
